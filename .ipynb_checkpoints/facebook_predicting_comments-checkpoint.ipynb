{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Facebook metrics Data Set - Predicting Number of Comments of Facebook Posts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To be completed INDIVIDUALLY and due on April 17 at 11:59pm. - Next Saturday**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, we will work on Facebook posts. The goal is to determine the number of comments a post will receive. Being able to predict the number of comments of a post can be viewed as predicting the impact a post will have, which makes this task quite challenging and interesting. You can find the dataset and details about it [here](https://archive.ics.uci.edu/ml/datasets/Facebook+metrics#) and [here](https://ac.els-cdn.com/S0148296316000813/1-s2.0-S0148296316000813-main.pdf?_tid=1944e5a8-e211-4dbc-bdd6-b233e4df6465&acdnat=1522453539_a59ca4034d01f4654986e45e18e79883). \n",
    "\n",
    "The data are stored in a .csv file and each row of the dataset corresponds to a distinct post (data instance). You will evaluate the performance of linear regression on the task of predicting the number of comments of a post.\n",
    "\n",
    "Relevant Papers/citations: _Prédictions d’activité dans les réseaux sociaux en ligne_ (F. Kawala, A. Douzal-Chouakria, E. Gaussier, E. Dimert), In Actes de la Conférence sur les Modèles et l′Analyse des Réseaux : Approches Mathématiques et Informatique (MARAMI), pp. 16, 2013."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1\n",
    "\n",
    "As learned in class most algorithms can only handle numeric values. However, in the given dataset you can see that the values of column 'Type' are categorical. Your first task is to prepare your dataset for linear regression and transform this column into numerical values. Note that creating a mapping that replaces the type field with a single number (e.g. Photo -> 1, Status ->2, Link ->3,...), will not be helpful here since the types are not ordered. Instead, use the \"indicator vector\" representation discussed in class. \n",
    "**(2 pt)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2\n",
    "\n",
    "Now your dataset is ready for linear regression. To familiarize yourself with this task, here simply use the following [package](http://www.statsmodels.org/dev/regression.html) to perform regression on the dataset. The dependent variable should be the column 'comment' and the remaining columns of your dataset should be the independent variables. Split your dataset into 80% and 20% for training and testing, respectively. Report the linear model's summary as shown [here](https://www.statsmodels.org/stable/index.html) by using the .summary() function after fitting your model and compute the error of your prediction using the [mean squared error (MSE)](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html).  **(2 pt)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provide an explanation of the OLS regression results. In particular, briefly explain and interpret: \n",
    "\n",
    "- R-squared, \n",
    "\n",
    "- coeff, \n",
    "\n",
    "Finally, \n",
    "\n",
    "- which are the statistically significant predictors and why? \n",
    "\n",
    "**(1 pt)** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3\n",
    "\n",
    "We will attempt to improve the MSE. In order to do so we are going to use regularization by returning a regularized fit to the linear regression model. Note that regularization's goal is to reduce overfitting, that is it creates a more generalized linear model and removes possible noise from the dataset. You will complete this task by using the .fit_regularized() method, and more specifically the **ridge fit**. More details can be found [here](http://www.statsmodels.org/dev/generated/statsmodels.regression.linear_model.OLS.fit_regularized.html). Perform Kfold cross-validation, where K = 5, to both the linear model and the regularized linear model, in order to decide which performs better. Report the MSE of the two models. Remember to shuffle the data before performing cross-validation. **(2 pt)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try the following values for the ridge regression parameter $\\alpha$ (the penalty weight), $\\alpha = [0,5,10,100]$.**(1 pt)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on your knowledge and your results, as a data scientist would you prefer a linear model, or a regularized linear model? What effects can a zero (or very small) $\\alpha$ and a very large $\\alpha$ cause?**(1 pt)** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4\n",
    "\n",
    "Another way that may help us improve the MSE is by adding quadratic terms of significant variables in the model. Add 2 quadratic terms in your **regularized linear model** based on two significant variables. An interesting and intuitive tutorial about understanding which are the significant variables and the importance of quadratic terms can be found [here](http://statisticsbyjim.com/regression/interpret-coefficients-p-values-regression/). Note that in order to add the quadratic terms you will need to change the formula of your model, as in [example](http://www.statsmodels.org/dev/examples/notebooks/generated/formulas.html) and in [example](https://stackoverflow.com/questions/31978948/python-stats-models-quadratic-term-in-regression/36539157). Perform Kfold cross-validation, where K = 5, to both the linear model and the regularized linear model with quadratic terms, in order to decide which performs better. Report the MSE of the two models. Remember to shuffle the data before performing cross-validation. **(2 pt)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What issues do you think could come up if we used too many quadratic or cubic terms in our model?**(1 pt)** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
